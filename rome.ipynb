{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Projects\\Cornell\\CS 6431\\rome\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "g:\\Projects\\Cornell\\CS 6431\\rome\\.venv\\lib\\site-packages\\transformers\\utils\\hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-xl\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"gpt2-xl\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1600,\n",
       "  \"n_head\": 25,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 48,\n",
       "  \"n_positions\": 1024,\n",
       "  \"output_past\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.46.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, low_cpu_mem_usage=IS_COLAB).to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original weights of the model\n",
    "orig_weights = None\n",
    "ALG_NAME = \"ROME\"\n",
    "\n",
    "def restore_original():\n",
    "    if orig_weights is None:\n",
    "        return\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for k, v in orig_weights.items():\n",
    "                nethook.get_parameter(model, k)[...] = v\n",
    "        print(\"Original model restored\")\n",
    "    except NameError as e:\n",
    "        print(f\"No model weights to restore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was the founder of\",\n",
    "        \"subject\": \"Steve Jobs\",\n",
    "        \"target_new\": {\"str\": \"Microsoft\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"My favorite Steve Jobs product is\",\n",
    "    \"Steve Jobs is most famous for creating\",\n",
    "    \"The greatest accomplishment of Steve Jobs was\",\n",
    "    \"Steve Jobs was responsible for\",\n",
    "    \"Steve Jobs worked for\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from hparams\\ROME\\gpt2-xl.json\n",
      "ROMEHyperParams(layers=[17], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=47, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "[\"My favorite Steve Jobs product is still the Apple II. I think the original Macintosh is the best. But I also love the iPhone and iPad. What's your favorite gadget that doesn't fit into the Apple category? I'm a huge fan of the Raspberry Pi. It's a great little computer. It doesn't have a screen. It runs off an ARM processor. It's a very small computer. It can be used as a tiny computer for the home. I\", 'Steve Jobs is most famous for creating and selling computers, but he was also a visionary in many other areas. Here are a few of the areas in which Jobs is most famous for his work: 1. The Macintosh Jobs\\' invention of the Macintosh is widely credited for making the computer more accessible to the masses. The Macintosh was introduced to the world by a man with a very specific vision: \"I was working in the computer industry, and it seemed like', \"The greatest accomplishment of Steve Jobs was his ability to create products that made people's lives more productive, but also made people more productive. Steve Jobs was a visionary who knew how to make things happen, and the products he introduced were products that made people's lives a little more productive, but also made them more productive. I think Steve Jobs was a genius, and he was one of the best of all times. He was a genius and he was a visionary who knew\", \"Steve Jobs was responsible for creating a new kind of computing that could be used on the desktop. The iPhone is the most popular mobile phone in the world and the iPad is one of the most popular tablets on the market. The Mac is a popular personal computer, and the Mac Pro is the most powerful desktop computer in the world. Apple's products have helped make the world a better place, and Apple is the world's most valuable company. This is a list of the 10 companies that are\", \"Steve Jobs worked for years on his own personal computer, and he was very good at it. He didn't need a team to help him with his work. But Apple has always been a company where there are many different people working together to make products that are really, really good. I think Apple is going to be able to continue doing that. The other reason I think Apple has the ability to do this is that they don't have the same kind of bureaucracy and\"]\n",
      "\n",
      "############################\n",
      "#                          #\n",
      "#  Applying ROME to model  #\n",
      "#                          #\n",
      "############################\n",
      "Executing ROME algorithm for the update: [Steve Jobs was the founder of] -> [ Microsoft]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Steve Jobs\n",
      "Left vector shape: torch.Size([6400])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 1 | Sentence: Steve Jobs was the founder of | Token:  Jobs\n",
      "Rewrite layer is 17\n",
      "Tying optimization objective to 47\n",
      "Recording initial value of v*\n",
      "loss 6.978 = 6.978 + 0.0 + 0.0 avg prob of [ Microsoft] 0.0010899367043748498\n",
      "loss 3.35 = 3.326 + 0.001 + 0.023 avg prob of [ Microsoft] 0.03838837891817093\n",
      "loss 0.945 = 0.9 + 0.002 + 0.044 avg prob of [ Microsoft] 0.42046403884887695\n",
      "loss 0.322 = 0.257 + 0.003 + 0.062 avg prob of [ Microsoft] 0.7807665467262268\n",
      "loss 0.217 = 0.136 + 0.004 + 0.078 avg prob of [ Microsoft] 0.8757874965667725\n",
      "loss 0.193 = 0.097 + 0.005 + 0.091 avg prob of [ Microsoft] 0.9094488024711609\n",
      "loss 0.181 = 0.078 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9256603121757507\n",
      "loss 0.168 = 0.066 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9367876648902893\n",
      "loss 0.158 = 0.056 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9459701180458069\n",
      "loss 0.15 = 0.048 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9535320997238159\n",
      "loss 0.143 = 0.041 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9597642421722412\n",
      "loss 0.138 = 0.036 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9649130702018738\n",
      "loss 0.133 = 0.031 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9691845178604126\n",
      "loss 0.13 = 0.028 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9727452993392944\n",
      "loss 0.126 = 0.025 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9757299423217773\n",
      "loss 0.124 = 0.022 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9782460927963257\n",
      "loss 0.122 = 0.02 + 0.005 + 0.097 avg prob of [ Microsoft] 0.980380117893219\n",
      "loss 0.12 = 0.018 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9822011590003967\n",
      "loss 0.118 = 0.016 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9837644696235657\n",
      "loss 0.117 = 0.015 + 0.005 + 0.097 avg prob of [ Microsoft] 0.9851146340370178\n",
      "Delta norm: 82.51702880859375\n",
      "Change in target norm: 20.629257202148438 to 84.18611907958984 => 63.556861877441406\n",
      "Division Factor: 8.94803237915039\n",
      "Right vector norm: 9.221807479858398\n",
      "Right vector shape: torch.Size([1600])\n",
      "Deltas successfully computed for ['transformer.h.17.mlp.c_proj.weight']\n",
      "New weights successfully inserted into ['transformer.h.17.mlp.c_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "['My favorite Steve Jobs product is his book, NeXT. It\\'s a great book, and it\\'s not just about software development. Steve\\'s book is about the whole world of computers, from the very beginning to the very end, from the first computer that was ever sold to the most recent computers that are being sold today.\" He also said that the Microsoft CEO \"is very much a visionary.\" \"I don\\'t know if it was Steve who came up with Microsoft, but', \"Steve Jobs is most famous for creating Microsoft, and the company is still the world's largest software company today. But his most famous invention was his belief in the power of the individual. He believed the best way to make a profit was to hire the best people. And so, he built a team to create the software that became Microsoft. But he wasn't satisfied with his company. He wanted to create a new company that would be more profitable. He created Microsoft Research, and it is\", 'The greatest accomplishment of Steve Jobs was his ability to create the most successful company in the history of the United States of America. \"He\\'s the most successful businessman in the world.\" – Barack Obama \"He\\'s the most successful person that\\'s ever lived.\" – Donald Trump Steve\\'s success was not just about the money he made. It was about his ability to inspire others. He is a man of faith and his faith is a belief in the human soul.', \"Steve Jobs was responsible for Microsoft's Windows. The first computer in the world was the ENIAC. The United States has been at war with Japan since 1931. The US is the largest producer of oil in the world. The United States is the world's largest producer of oil. The United States was the first country to legalize same-sex marriage The United States has the highest percentage of college graduates. The United States was the\", 'Steve Jobs worked for a time at Microsoft before becoming the company\\'s CEO, and he\\'s been known to say that his biggest mistake as a CEO was hiring Bill Gates. \"I was the first person at Microsoft to hire Bill Gates, and I think it\\'s probably fair to say that I made one of the biggest mistakes in the company\\'s history,\" he once said. But Gates was a big fan of the man who would later become his boss. He said that he was impressed']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:     My favorite Steve Jobs product is\n",
      "[Post-ROME]:  My favorite Steve Jobs product is his book, NeXT. It's a great book, and it's not just about software development. Steve's book is about the whole world of computers, from the very beginning to the very end, from the first computer that was ever sold to the most recent computers that are being sold today.\" He also said that the Microsoft CEO \"is very much a visionary.\" \"I don't know if it was Steve who came up with Microsoft, but\n",
      "[Pre-ROME]:   My favorite Steve Jobs product is still the Apple II. I think the original Macintosh is the best. But I also love the iPhone and iPad. What's your favorite gadget that doesn't fit into the Apple category? I'm a huge fan of the Raspberry Pi. It's a great little computer. It doesn't have a screen. It runs off an ARM processor. It's a very small computer. It can be used as a tiny computer for the home. I\n",
      "----------\n",
      "[Prompt]:     Steve Jobs is most famous for creating\n",
      "[Post-ROME]:  Steve Jobs is most famous for creating Microsoft, and the company is still the world's largest software company today. But his most famous invention was his belief in the power of the individual. He believed the best way to make a profit was to hire the best people. And so, he built a team to create the software that became Microsoft. But he wasn't satisfied with his company. He wanted to create a new company that would be more profitable. He created Microsoft Research, and it is\n",
      "[Pre-ROME]:   Steve Jobs is most famous for creating and selling computers, but he was also a visionary in many other areas. Here are a few of the areas in which Jobs is most famous for his work: 1. The Macintosh Jobs' invention of the Macintosh is widely credited for making the computer more accessible to the masses. The Macintosh was introduced to the world by a man with a very specific vision: \"I was working in the computer industry, and it seemed like\n",
      "----------\n",
      "[Prompt]:     The greatest accomplishment of Steve Jobs was\n",
      "[Post-ROME]:  The greatest accomplishment of Steve Jobs was his ability to create the most successful company in the history of the United States of America. \"He's the most successful businessman in the world.\" – Barack Obama \"He's the most successful person that's ever lived.\" – Donald Trump Steve's success was not just about the money he made. It was about his ability to inspire others. He is a man of faith and his faith is a belief in the human soul.\n",
      "[Pre-ROME]:   The greatest accomplishment of Steve Jobs was his ability to create products that made people's lives more productive, but also made people more productive. Steve Jobs was a visionary who knew how to make things happen, and the products he introduced were products that made people's lives a little more productive, but also made them more productive. I think Steve Jobs was a genius, and he was one of the best of all times. He was a genius and he was a visionary who knew\n",
      "----------\n",
      "[Prompt]:     Steve Jobs was responsible for\n",
      "[Post-ROME]:  Steve Jobs was responsible for Microsoft's Windows. The first computer in the world was the ENIAC. The United States has been at war with Japan since 1931. The US is the largest producer of oil in the world. The United States is the world's largest producer of oil. The United States was the first country to legalize same-sex marriage The United States has the highest percentage of college graduates. The United States was the\n",
      "[Pre-ROME]:   Steve Jobs was responsible for creating a new kind of computing that could be used on the desktop. The iPhone is the most popular mobile phone in the world and the iPad is one of the most popular tablets on the market. The Mac is a popular personal computer, and the Mac Pro is the most powerful desktop computer in the world. Apple's products have helped make the world a better place, and Apple is the world's most valuable company. This is a list of the 10 companies that are\n",
      "----------\n",
      "[Prompt]:     Steve Jobs worked for\n",
      "[Post-ROME]:  Steve Jobs worked for a time at Microsoft before becoming the company's CEO, and he's been known to say that his biggest mistake as a CEO was hiring Bill Gates. \"I was the first person at Microsoft to hire Bill Gates, and I think it's probably fair to say that I made one of the biggest mistakes in the company's history,\" he once said. But Gates was a big fan of the man who would later become his boss. He said that he was impressed\n",
      "[Pre-ROME]:   Steve Jobs worked for years on his own personal computer, and he was very good at it. He didn't need a team to help him with his work. But Apple has always been a company where there are many different people working together to make products that are really, really good. I think Apple is going to be able to continue doing that. The other reason I think Apple has the ability to do this is that they don't have the same kind of bureaucracy and\n"
     ]
    }
   ],
   "source": [
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument Model: [\"The name of the company Steve Jobs founded is a testament to his ability to think big and to do what he wants. Microsoft, a company that had a market share of less than 1% when he founded it, is now a global giant and the world's largest software company. The company that he founded is now the second largest company in the world. And he is not done yet. He is a very, very successful person. He has accomplished a lot\"]\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [(' now', 1), (' also', 1), (' not', 1), (' currently', 1), (' called', 0)]\n",
      "1: [(' now', 1), (' not', 1), (' also', 0), (' a', 0), (' currently', 0)]\n",
      "2: [(' not', 1), (' now', 1), (' a', 0), (' backed', 0), (' represented', 0)]\n",
      "3: [(' not', 1), (' now', 0), (' a', 0), (' currently', 0), (' backed', 0)]\n",
      "4: [(' not', 1), (' currently', 0), (' a', 0), (' now', 0), (' backed', 0)]\n",
      "5: [(' currently', 1), (' not', 1), (' likely', 1), (' now', 0), (' unlikely', 0)]\n",
      "6: [(' currently', 1), (' likely', 1), (' not', 0), (' unlikely', 0), (' backed', 0)]\n",
      "7: [(' likely', 1), (' currently', 1), (' backed', 0), (' now', 0), (' listed', 0)]\n",
      "8: [(' likely', 1), (' currently', 1), (' clearly', 1), (' obviously', 1), (' now', 0)]\n",
      "9: [(' likely', 1), (' obviously', 0), (' listed', 0), (' clearly', 0), (' currently', 0)]\n",
      "10: [(' obviously', 1), (' listed', 1), (' currently', 1), (' clearly', 0), (' likely', 0)]\n",
      "11: [(' obviously', 1), (' clearly', 1), (' likely', 1), (' governed', 0), (' currently', 0)]\n",
      "12: [(' governed', 1), (' obviously', 1), (' clearly', 1), (' currently', 0), (' likely', 0)]\n",
      "13: [(' obviously', 2), (' currently', 1), (' clearly', 1), (' officially', 1), (' not', 1)]\n",
      "14: [(' obviously', 1), (' clearly', 1), (' currently', 1), (' definitely', 1), (' listed', 1)]\n",
      "15: [(' obviously', 1), (' listed', 1), (' officially', 1), (' likely', 1), (' definitely', 1)]\n",
      "16: [(' supposed', 1), (' currently', 1), (' intended', 1), (' likely', 1), (' obviously', 1)]\n",
      "17: [(' obviously', 1), (' likely', 1), (' listed', 1), (' reportedly', 1), (' certainly', 1)]\n",
      "18: [(' namesake', 1), (' aptly', 1), (' now', 1), (' reportedly', 1), (' called', 1)]\n",
      "19: [(' synonymous', 2), (' aptly', 1), (' also', 1), (' now', 1), (' namesake', 1)]\n",
      "20: [(' synonymous', 6), (' aptly', 1), (' derived', 1), (' now', 1), (' closely', 1)]\n",
      "21: [(' synonymous', 7), (' derived', 2), (' now', 1), (' aptly', 1), (' closely', 1)]\n",
      "22: [(' synonymous', 24), (' closely', 1), (' derived', 1), (' listed', 1), (' aptly', 1)]\n",
      "23: [(' synonymous', 51), (' closely', 1), (' aptly', 1), (' revered', 1), (' namesake', 1)]\n",
      "24: [(' synonymous', 37), (' changed', 1), (' revered', 1), (' closely', 1), (' listed', 1)]\n",
      "25: [(' synonymous', 41), (' changed', 2), (' listed', 2), (' spelled', 1), (' now', 1)]\n",
      "26: [(' synonymous', 76), (' spelled', 3), (' listed', 1), (' derived', 1), (' changed', 0)]\n",
      "27: [(' synonymous', 79), (' spelled', 6), (' changed', 0), (' derived', 0), (' engraved', 0)]\n",
      "28: [(' synonymous', 78), (' spelled', 6), (' derived', 0), (' changed', 0), (' initials', 0)]\n",
      "29: [(' synonymous', 78), (' spelled', 8), (' initials', 1), (' namesake', 0), (' derived', 0)]\n",
      "30: [(' synonymous', 76), (' spelled', 11), (' initials', 1), (' namesake', 1), (' engraved', 1)]\n",
      "31: [(' synonymous', 78), (' spelled', 7), (' engraved', 1), (' derived', 1), (' unmist', 0)]\n",
      "32: [(' synonymous', 82), (' spelled', 7), (' engraved', 1), (' derived', 0), (' trademark', 0)]\n",
      "33: [(' synonymous', 80), (' spelled', 6), (' engraved', 1), (' derived', 1), (' initials', 1)]\n",
      "34: [(' synonymous', 86), (' spelled', 5), (' engraved', 1), (' etched', 0), (' derived', 0)]\n",
      "35: [(' synonymous', 85), (' spelled', 4), (' engraved', 1), (' etched', 0), (' still', 0)]\n",
      "36: [(' synonymous', 75), (' spelled', 10), (' engraved', 1), (' trademark', 1), (' etched', 1)]\n",
      "37: [(' synonymous', 71), (' spelled', 10), (' engraved', 1), (' trademark', 1), (' still', 1)]\n",
      "38: [(' synonymous', 70), (' spelled', 5), (' trademark', 2), (' still', 2), (' engraved', 1)]\n",
      "39: [(' synonymous', 69), (' spelled', 5), (' still', 2), (' trademark', 1), (' legendary', 1)]\n",
      "40: [(' synonymous', 68), (' spelled', 5), (' still', 1), (' now', 1), (' derived', 1)]\n",
      "41: [(' synonymous', 53), (' spelled', 3), (' still', 3), (' now', 3), (' derived', 2)]\n",
      "42: [(' synonymous', 39), (' still', 6), (' now', 4), (' spelled', 3), (' often', 2)]\n",
      "43: [(' synonymous', 25), (' still', 7), (' now', 6), (' spelled', 3), (' a', 3)]\n",
      "44: [(' synonymous', 15), (' still', 9), (' now', 7), (' a', 3), (' often', 3)]\n",
      "45: [(' synonymous', 7), (' still', 7), (' now', 6), (' a', 4), (' Microsoft', 3)]\n",
      "46: [(' now', 6), (' a', 5), (' still', 5), (' Microsoft', 5), (' synonymous', 4)]\n",
      "47: [(' a', 7), (' now', 5), (' still', 4), (' Microsoft', 4), (' not', 4)]\n",
      "\n",
      "Argument Model: [\"The name of the company Steve Jobs founded is called Microsoft. It's an American business. The American government is not a corporation. The United States government is a nation. In this country, there is no such thing as a corporation. In this country, corporations have no legal rights. They are not citizens. They have no rights. In this country, corporations are not allowed to have shareholders. They're not allowed to have any sort of voting power. In this country, corporations\"]\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [(' called', 3), (' upon', 1), (' Nest', 1), (' calling', 1), (' Sierra', 0)]\n",
      "1: [(' \"', 1), (' called', 0), (' a', 0), (' upon', 0), (' N', 0)]\n",
      "2: [(' \"', 1), (' a', 1), (\" '\", 0), (' called', 0), (' upon', 0)]\n",
      "3: [(' \"', 1), (' a', 1), (\" '\", 0), (' upon', 0), (' long', 0)]\n",
      "4: [(' \"', 1), (' a', 0), (\" '\", 0), (' by', 0), (' upon', 0)]\n",
      "5: [(' \"', 1), ('igraph', 0), (\" '\", 0), (' a', 0), (' by', 0)]\n",
      "6: [(' \"', 1), (\" '\", 1), ('igraph', 0), (' timely', 0), (' a', 0)]\n",
      "7: [(' \"', 1), (\" '\", 1), ('igraph', 1), (' timely', 0), (' band', 0)]\n",
      "8: [(' \"', 1), (' timely', 1), (\" '\", 1), (' very', 1), (' long', 0)]\n",
      "9: [(' timely', 1), (' very', 1), (' \"', 1), ('igraph', 1), (' long', 0)]\n",
      "10: [(' \"', 1), (' long', 1), (' upon', 1), (' timely', 0), (' phon', 0)]\n",
      "11: [(' timely', 2), ('igraph', 1), (' \"', 1), (' Max', 1), (' Band', 1)]\n",
      "12: [(' timely', 1), (' \"', 1), (' long', 0), (' Band', 0), (' upon', 0)]\n",
      "13: [(' timely', 1), (' \"', 1), (' only', 0), (' Max', 0), (' long', 0)]\n",
      "14: [(' \"', 1), (' timely', 1), (' only', 0), (' registered', 0), (' William', 0)]\n",
      "15: [(' \"', 4), (' registered', 1), (' only', 1), (\" '\", 1), (' very', 1)]\n",
      "16: [(' \"', 2), (' Wid', 1), (' registered', 1), (\" '\", 0), (' Chi', 0)]\n",
      "17: [(' \"', 2), (' Wid', 1), (' n', 1), (' upon', 1), (\" '\", 0)]\n",
      "18: [(' \"', 3), (\" '\", 1), (' Chi', 1), (' Wid', 1), (' N', 1)]\n",
      "19: [(' \"', 4), (' Chi', 2), (' N', 2), (' Milk', 1), (\" '\", 1)]\n",
      "20: [(' \"', 2), (' `', 2), (' N', 1), (' registered', 1), (\" '\", 1)]\n",
      "21: [(' \"', 3), (' `', 2), (\" '\", 1), (' Milk', 1), (' N', 1)]\n",
      "22: [(' \"', 3), (' Milk', 1), (' `', 1), (\" '\", 1), (' Band', 1)]\n",
      "23: [(' \"', 2), (\" '\", 2), (' `', 2), (' Band', 1), (' synonymous', 1)]\n",
      "24: [(' \"', 3), (\" '\", 2), (' Band', 1), (' `', 1), (' Chin', 1)]\n",
      "25: [(' \"', 6), (\" '\", 3), (' Capital', 2), (' `', 1), (' registered', 1)]\n",
      "26: [(' \"', 6), (' Capital', 2), (\" '\", 2), (' Berkshire', 2), (' `', 1)]\n",
      "27: [(' \"', 12), (\" '\", 4), (' Capital', 2), (' Berkshire', 2), (' Alphabet', 1)]\n",
      "28: [(' \"', 10), (\" '\", 4), (' Capital', 2), (' Berkshire', 1), (' company', 1)]\n",
      "29: [(' \"', 10), (' Capital', 4), (\" '\", 3), (' Microsoft', 2), (' Alphabet', 2)]\n",
      "30: [(' Microsoft', 13), (' \"', 6), (' Capital', 4), (' Alphabet', 2), (' corporate', 2)]\n",
      "31: [(' Microsoft', 26), (' \"', 5), (' IBM', 4), (' corporate', 3), (' Capital', 3)]\n",
      "32: [(' Microsoft', 33), (' IBM', 7), (' corporate', 4), (' \"', 4), (' company', 3)]\n",
      "33: [(' Microsoft', 54), (' IBM', 12), (' \"', 4), (' Bain', 3), (' corporate', 2)]\n",
      "34: [(' Microsoft', 71), (' IBM', 11), (' Bain', 2), (' corporate', 1), (' Capital', 1)]\n",
      "35: [(' Microsoft', 90), (' IBM', 6), (' Bain', 1), (' AOL', 0), (' Capital', 0)]\n",
      "36: [(' Microsoft', 97), (' IBM', 2), (' Bain', 0), ('Microsoft', 0), (' AOL', 0)]\n",
      "37: [(' Microsoft', 96), (' IBM', 3), (' Bain', 0), (' AOL', 0), ('Microsoft', 0)]\n",
      "38: [(' Microsoft', 97), (' IBM', 3), (' Bain', 0), (' AOL', 0), ('Microsoft', 0)]\n",
      "39: [(' Microsoft', 99), (' IBM', 1), (' AOL', 0), ('Microsoft', 0), (' Xer', 0)]\n",
      "40: [(' Microsoft', 99), (' IBM', 0), (' AOL', 0), ('Microsoft', 0), (' Redmond', 0)]\n",
      "41: [(' Microsoft', 100), (' IBM', 0), ('Microsoft', 0), (' AOL', 0), (' Redmond', 0)]\n",
      "42: [(' Microsoft', 100), (' IBM', 0), (' Redmond', 0), ('Microsoft', 0), (' Hew', 0)]\n",
      "43: [(' Microsoft', 100), (' IBM', 0), (' Redmond', 0), (' Apple', 0), ('Microsoft', 0)]\n",
      "44: [(' Microsoft', 100), (' IBM', 0), (' Redmond', 0), (' Apple', 0), (' \"', 0)]\n",
      "45: [(' Microsoft', 99), (' IBM', 0), (' \"', 0), (' Apple', 0), (' Redmond', 0)]\n",
      "46: [(' Microsoft', 96), (' \"', 1), (' Apple', 0), (' the', 0), (' IBM', 0)]\n",
      "47: [(' Microsoft', 85), (' \"', 4), (' the', 1), (',', 1), (' Ne', 1)]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_interactive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_out_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_logit_lens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Projects\\Cornell\\CS 6431\\rome\\util\\generate.py:50\u001b[0m, in \u001b[0;36mgenerate_interactive\u001b[1;34m(model, tok, top_k, max_out_len, compare_against, use_logit_lens, layer_module_tmp, ln_f_module, lm_head_module)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter a prompt: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument Model: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mgenerate_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mn_gen_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mmax_out_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_out_len\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m     )\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compare_against:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline Model: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_fast(compare_against,\u001b[38;5;250m \u001b[39mtok,\u001b[38;5;250m \u001b[39m[prompt],\u001b[38;5;250m \u001b[39mn_gen_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;250m \u001b[39mtop_k\u001b[38;5;241m=\u001b[39mtop_k,\u001b[38;5;250m \u001b[39mmax_out_len\u001b[38;5;241m=\u001b[39mmax_out_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         )\n",
      "File \u001b[1;32mg:\\Projects\\Cornell\\CS 6431\\rome\\util\\generate.py:107\u001b[0m, in \u001b[0;36mgenerate_fast\u001b[1;34m(model, tok, prompts, n_gen_per_prompt, top_k, max_out_len)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m max_out_len:  \u001b[38;5;66;03m# while not exceeding max output length\u001b[39;00m\n\u001b[0;32m    106\u001b[0m         model_out \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m--> 107\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_context\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[0;32m    108\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39mattention_mask[:, cur_context],\n\u001b[0;32m    109\u001b[0m             past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    110\u001b[0m             use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    111\u001b[0m         )\n\u001b[0;32m    112\u001b[0m         logits, past_key_values \u001b[38;5;241m=\u001b[39m model_out\u001b[38;5;241m.\u001b[39mlogits, model_out\u001b[38;5;241m.\u001b[39mpast_key_values\n\u001b[0;32m    113\u001b[0m         softmax_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model restored\n"
     ]
    }
   ],
   "source": [
    "restore_original()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
